{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification CIFAR-10 using CNN\n",
        "## Importing libraries"
      ],
      "metadata": {
        "id": "zgA_OvhAAhcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library jika diperlukan (khusus Google Colab)\n",
        "!pip install torch torchvision scikit-learn matplotlib\n",
        "\n",
        "# Import library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz4NxjCMAjGk",
        "outputId": "aaf3b100-794f-4a5f-e86a-959de07a2771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Gunakan transformasi ini saat ambil data\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Label nama kelas\n",
        "classes = trainset.classes\n"
      ],
      "metadata": {
        "id": "ek8coafXAq94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Model 1: CNN (Convolutional Neural Network)"
      ],
      "metadata": {
        "id": "QcZFF9H1BKl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "RyLuHG3PBNly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Model 2: MLP (Multilayer Perceptron) Vanilla"
      ],
      "metadata": {
        "id": "GyDATU2pBTk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPVanilla(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPVanilla, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 32 * 3, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "Y1p_o3hBBS7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚙️ Training & Evaluation Function"
      ],
      "metadata": {
        "id": "1VrYaGYRBaXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, loader, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    y_true, y_pred, y_score = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            y_score.extend(probs.cpu().numpy())\n",
        "\n",
        "    return np.array(y_true), np.array(y_pred), np.array(y_score)\n"
      ],
      "metadata": {
        "id": "6DKse3adBcJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🚀 Jalankan Training untuk CNN"
      ],
      "metadata": {
        "id": "iCCVUAWrBe-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(10):\n",
        "    loss = train(model, optimizer, criterion, trainloader, device)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sViKw99nBgrw",
        "outputId": "0ea1703f-773a-4042-f40a-03e67fcaba7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.5216\n",
            "Epoch 2, Loss: 1.0965\n",
            "Epoch 3, Loss: 0.9017\n",
            "Epoch 4, Loss: 0.7945\n",
            "Epoch 5, Loss: 0.7142\n",
            "Epoch 6, Loss: 0.6576\n",
            "Epoch 7, Loss: 0.6085\n",
            "Epoch 8, Loss: 0.5669\n",
            "Epoch 9, Loss: 0.5338\n",
            "Epoch 10, Loss: 0.5005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Evaluasi CNN"
      ],
      "metadata": {
        "id": "Y8B5D8FzB6AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred, y_score = evaluate(model, testloader, device)\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred, average='macro')\n",
        "rec = recall_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# ROC AUC Macro (multi-class)\n",
        "try:\n",
        "    auc = roc_auc_score(y_true, y_score, multi_class='ovo', average='macro')\n",
        "except:\n",
        "    auc = 'Error (label mismatch)'\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"AUC Score: {auc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH1vyS3AB8jn",
        "outputId": "6f18f181-3781-4252-96af-77b1286082f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8215\n",
            "Precision: 0.8339\n",
            "Recall: 0.8215\n",
            "F1 Score: 0.8230\n",
            "AUC Score: 0.9834238944444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ CNN Test Accuracy"
      ],
      "metadata": {
        "id": "xhujXfxZCUeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tambahkan akurasi dalam bentuk persen\n",
        "acc_percent = acc * 100\n",
        "print(f\"CNN Test Accuracy : {acc_percent:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HknbMbBCYcM",
        "outputId": "3e8685e1-daac-478d-a24e-3e5e7088fdcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Test Accuracy : 82.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🚀 Training untuk MLP Vanilla"
      ],
      "metadata": {
        "id": "8ALglBLgDg52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp = MLPVanilla().to(device)\n",
        "optimizer_mlp = optim.Adam(model_mlp.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    loss = train(model_mlp, optimizer_mlp, criterion, trainloader, device)\n",
        "    print(f\"MLP Epoch {epoch+1}, Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jevPZIIuDgLV",
        "outputId": "b6d24efa-1dcf-4528-c63b-f2d162ce8e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Epoch 1, Loss: 1.8368\n",
            "MLP Epoch 2, Loss: 1.6599\n",
            "MLP Epoch 3, Loss: 1.5772\n",
            "MLP Epoch 4, Loss: 1.5290\n",
            "MLP Epoch 5, Loss: 1.4917\n",
            "MLP Epoch 6, Loss: 1.4719\n",
            "MLP Epoch 7, Loss: 1.4428\n",
            "MLP Epoch 8, Loss: 1.4278\n",
            "MLP Epoch 9, Loss: 1.4104\n",
            "MLP Epoch 10, Loss: 1.3953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Evaluasi MLP"
      ],
      "metadata": {
        "id": "j3ubs9yVDlLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi MLP\n",
        "y_true_mlp, y_pred_mlp, y_score_mlp = evaluate(model_mlp, testloader, device)\n",
        "\n",
        "acc_mlp = accuracy_score(y_true_mlp, y_pred_mlp)\n",
        "prec_mlp = precision_score(y_true_mlp, y_pred_mlp, average='macro')\n",
        "rec_mlp = recall_score(y_true_mlp, y_pred_mlp, average='macro')\n",
        "f1_mlp = f1_score(y_true_mlp, y_pred_mlp, average='macro')\n",
        "\n",
        "# ROC AUC untuk MLP\n",
        "try:\n",
        "    auc_mlp = roc_auc_score(y_true_mlp, y_score_mlp, multi_class='ovo', average='macro')\n",
        "except:\n",
        "    auc_mlp = 'Error (label mismatch)'\n",
        "\n",
        "# Output hasil evaluasi\n",
        "print(f\"MLP Accuracy: {acc_mlp:.4f}\")\n",
        "print(f\"MLP Precision: {prec_mlp:.4f}\")\n",
        "print(f\"MLP Recall: {rec_mlp:.4f}\")\n",
        "print(f\"MLP F1 Score: {f1_mlp:.4f}\")\n",
        "print(f\"MLP AUC Score: {auc_mlp}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkH150K-DnVk",
        "outputId": "81d053cf-2690-4603-c00a-a3c9fb5f0275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Accuracy: 0.4540\n",
            "MLP Precision: 0.4577\n",
            "MLP Recall: 0.4540\n",
            "MLP F1 Score: 0.4478\n",
            "MLP AUC Score: 0.8616842944444446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi akurasi ke persentase\n",
        "acc_percent_mlp = acc_mlp * 100\n",
        "print(f\"MLP Accuracy (in %): {acc_percent_mlp:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3jKwi4KD69U",
        "outputId": "e53df449-f66c-4f65-e7ad-d75fea2af930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Accuracy (in %): 45.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kesimpulan\n",
        "\n",
        "Berdasarkan hasil evaluasi yang diperoleh dari model **CNN** dan **MLP** pada dataset **CIFAR-10**, berikut adalah beberapa poin utama yang dapat disimpulkan:\n",
        "\n",
        "## 1. **Model CNN:**\n",
        "- **Akurasi**: Model CNN mencapai akurasi **82.15%**, yang menunjukkan bahwa model ini cukup baik dalam mengenali pola dan fitur pada dataset CIFAR-10.\n",
        "- **Precision**: Dengan **83.39%**, model CNN memiliki precision yang baik, artinya sebagian besar prediksi positif yang dilakukan oleh model benar-benar positif.\n",
        "- **Recall**: **82.15%**, yang menunjukkan bahwa model mampu mendeteksi sebagian besar data positif yang ada.\n",
        "- **F1 Score**: **82.30%**, ini menunjukkan keseimbangan yang baik antara precision dan recall. Model CNN mampu menjaga kinerja baik pada kedua metrik tersebut.\n",
        "- **AUC Score**: **98.34%**, yang sangat tinggi dan menunjukkan bahwa model CNN memiliki kemampuan sangat baik dalam membedakan antara kelas-kelas yang ada, dengan sedikit kesalahan dalam memprediksi kelas negatif.\n",
        "\n",
        "## 2. **Model MLP:**\n",
        "- **Akurasi**: Model MLP hanya mencapai **45.40%** akurasi, yang jauh lebih rendah dibandingkan dengan CNN. Hal ini menunjukkan bahwa MLP kurang efektif untuk tugas klasifikasi gambar seperti CIFAR-10.\n",
        "- **Precision**: Dengan **45.77%**, MLP menunjukkan kemampuan yang terbatas dalam memberikan prediksi positif yang benar.\n",
        "- **Recall**: **45.40%**, ini menunjukkan bahwa MLP kurang mampu mendeteksi sebagian besar data positif yang ada.\n",
        "- **F1 Score**: **44.78%**, yang juga mencerminkan bahwa model ini tidak seimbang dalam hal precision dan recall.\n",
        "- **AUC Score**: **86.17%**, meskipun lebih rendah dari CNN, AUC untuk MLP masih menunjukkan bahwa model ini cukup baik dalam membedakan kelas-kelas, meskipun tidak sebaik CNN.\n",
        "\n",
        "## 3. **Kesimpulan Umum:**\n",
        "- **CNN** menunjukkan kinerja yang jauh lebih baik dibandingkan dengan **MLP** pada dataset **CIFAR-10**, dengan akurasi yang jauh lebih tinggi dan metrik evaluasi lainnya yang mendekati nilai maksimum.\n",
        "- **MLP**, meskipun lebih sederhana, kesulitan untuk mencapai hasil yang baik pada tugas klasifikasi gambar yang kompleks. Ini menunjukkan bahwa **MLP tidak cocok untuk menangani data gambar**, karena tidak memiliki mekanisme untuk menangkap fitur spasial dalam gambar seperti yang dilakukan oleh **CNN**.\n",
        "- Oleh karena itu, untuk tugas klasifikasi gambar yang kompleks seperti CIFAR-10, **CNN adalah pilihan yang lebih baik** karena dapat memanfaatkan fitur spasial dan hubungan antar piksel dalam gambar.\n",
        "\n",
        "Secara keseluruhan, **CNN** terbukti lebih unggul dalam mengatasi masalah klasifikasi gambar pada dataset CIFAR-10.\n"
      ],
      "metadata": {
        "id": "tK5meGQrRrKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Penjelasan Persamaan Matematika\n",
        "## 1. **Cross-Entropy Loss (Loss Function)**\n",
        "Cross-Entropy Loss digunakan untuk mengukur perbedaan antara distribusi probabilitas prediksi model dan distribusi probabilitas label yang sebenarnya.\n",
        "\n",
        "$$\n",
        "\\text{Loss} = - \\sum_{i=1}^{N} y_i \\cdot \\log(p_i)\n",
        "$$\n",
        "\n",
        "- \\( y_i \\): Nilai sebenarnya (label) untuk kelas ke-\\(i\\) (biasanya dalam bentuk one-hot encoding).\n",
        "- \\( p_i \\): Probabilitas prediksi untuk kelas ke-\\(i\\) (hasil dari fungsi Softmax).\n",
        "- \\( N \\): Jumlah kelas.\n",
        "- **Fungsi ini mengukur seberapa baik model dalam memprediksi kelas yang benar.** Semakin kecil nilai loss, semakin baik performa model.\n",
        "\n",
        "## 2. **Accuracy**\n",
        "Akurasi mengukur seberapa banyak prediksi yang benar dibandingkan dengan total data yang ada.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Jumlah Prediksi Benar}}{\\text{Jumlah Data Total}}\n",
        "$$\n",
        "\n",
        "- **Akurasi** menunjukkan **seberapa sering model memberikan prediksi yang benar**.\n",
        "\n",
        "## 3. **Precision**\n",
        "Precision mengukur seberapa banyak prediksi yang benar untuk kelas positif dibandingkan dengan jumlah semua prediksi positif.\n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "- \\( TP \\) (True Positives): Jumlah kasus di mana model dengan benar memprediksi kelas positif.\n",
        "- \\( FP \\) (False Positives): Jumlah kasus di mana model salah memprediksi kelas positif (seharusnya negatif).\n",
        "- Precision menunjukkan **seberapa banyak prediksi positif yang benar** dari total prediksi positif yang dibuat oleh model.\n",
        "\n",
        "## 4. **Recall**\n",
        "Recall mengukur seberapa banyak data positif yang benar-benar terdeteksi oleh model dari semua data yang seharusnya positif.\n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "- \\( FN \\) (False Negatives): Jumlah kasus di mana model salah memprediksi kelas negatif padahal data tersebut seharusnya positif.\n",
        "- Recall menunjukkan **seberapa baik model dalam mendeteksi kelas positif**.\n",
        "\n",
        "## 5. **F1 Score**\n",
        "F1 Score adalah rata-rata harmonis dari Precision dan Recall. F1 score memberikan gambaran yang lebih lengkap mengenai keseimbangan antara Precision dan Recall.\n",
        "\n",
        "$$\n",
        "\\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "- F1 score memberikan **ukuran tunggal** yang menggambarkan keseimbangan antara Precision dan Recall. Nilai F1 akan mendekati 1 jika kedua metrik tersebut tinggi.\n",
        "\n",
        "## 6. **AUC (Area Under Curve) dan ROC (Receiver Operating Characteristic)**\n",
        "AUC adalah **area di bawah kurva ROC**. Kurva ROC menunjukkan hubungan antara **True Positive Rate (TPR)** dan **False Positive Rate (FPR)**, yang digunakan untuk mengukur kinerja model dalam membedakan antara kelas positif dan negatif.\n",
        "\n",
        "$$\n",
        "\\text{TPR (Recall)} = \\frac{TP}{TP + FN}, \\quad \\text{FPR} = \\frac{FP}{FP + TN}\n",
        "$$\n",
        "\n",
        "- **AUC** mengukur seberapa baik model dapat memisahkan antara kelas positif dan kelas negatif. Nilai AUC mendekati 1 berarti model sangat baik dalam membedakan kedua kelas.\n",
        "- **ROC Curve** adalah grafik yang menggambarkan hubungan antara TPR dan FPR pada berbagai threshold.\n",
        "\n",
        "## 7. **Softmax Function**\n",
        "Softmax digunakan pada model klasifikasi multi-kelas untuk menghasilkan probabilitas dari output yang tidak terdistribusi secara probabilistik.\n",
        "\n",
        "$$\n",
        "\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}\n",
        "$$\n",
        "\n",
        "- \\( z_i \\) adalah skor mentah (logit) untuk kelas ke-\\(i\\).\n",
        "- \\( K \\) adalah jumlah total kelas.\n",
        "- Softmax mengubah nilai logit menjadi nilai probabilitas antara 0 dan 1, yang menjumlahkan seluruh probabilitas untuk kelas-kelas menjadi 1.\n",
        "\n",
        "---\n",
        "\n",
        "# Ringkasan\n",
        "- **Cross-Entropy Loss** digunakan untuk menghitung seberapa baik model dalam memprediksi distribusi probabilitas untuk kelas-kelas.\n",
        "- **Akurasi** menunjukkan seberapa sering model memprediksi dengan benar.\n",
        "- **Precision** dan **Recall** mengukur kualitas prediksi positif, dengan Precision lebih fokus pada **keakuratan** prediksi positif dan Recall lebih pada **kemampuan mendeteksi** positif.\n",
        "- **F1 Score** menggabungkan Precision dan Recall untuk memberikan satu metrik.\n",
        "- **AUC** dan **ROC Curve** menggambarkan seberapa baik model membedakan antara kelas-kelas yang berbeda.\n",
        "\n",
        "Metrik-metrik ini sangat penting dalam mengevaluasi performa model, terutama dalam klasifikasi yang melibatkan lebih dari dua kelas atau ketidakseimbangan antara kelas.\n"
      ],
      "metadata": {
        "id": "qN6V-6vzQomq"
      }
    }
  ]
}